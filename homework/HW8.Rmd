---
title: Assignment 8
author: "Melissa Wong"
date: \today
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r libraries, results='hide', message=FALSE, warning=FALSE}

library(tidyverse)
library(RColorBrewer)
#library(rethinking)
library(gridExtra)
library(tidybayes)
library(bayesplot)
#library(rstan)
library(dagitty)
library(here)
library(brms)
library(cmdstanr)
```

```{r options}
options("scipen" = 1, "digits" = 4)

#knitr::opts_chunk$set(echo = FALSE)
#knitr::opts_chunk$set(message = FALSE)
#knitr::opts_chunk$set(warning = FALSE)
#knitr::opts_chunk$set(out.width = "50%")
knitr::opts_chunk$set(fig.align = "center")

# Set Default ggplot palette
options(ggplot2.discrete.color=brewer.pal(8, "Dark2"))
options(ggplot2.discrete.fill=brewer.pal(8, "Dark2"))

set_cmdstan_path(here("../.cmdstanr/cmdstan-2.27.0"))
ncores <- min(4, parallel::detectCores()-1)

# Set brms backend to cmdstanr
options(brms.backend="cmdstanr")
```

# Problem 1
```{r}
data("reedfrogs", package="rethinking")

frogs <- reedfrogs %>% 
  select(surv, density, pred, size) %>% 
  mutate(tank = row_number())
```

## Varying Intercepts Model

```{r results="hide"}
# Varying intercepts model
mdl1 <- brm(surv | trials(density) ~ 1 + (1 | tank),
            prior = c(set_prior("normal(0,2)", class="Intercept"),
                      set_prior("exponential(1)", class="sd")),
            data=frogs,
            family=binomial(link="logit"),
            chains=4,
            cores=ncores,
            file_refit = "on_change",
            file = here("homework/mdl8-1.rds")
            )

#get_variables(mdl1)

```

```{r}
summary(mdl1)

mcmc_plot(mdl1, type="intervals",
          pars=c("^b_", "^sd_"),
          prob=0.5, prob_outer=0.95,
          point_est="median")
```

```{r}
mcmc_rank_overlay(mdl1,           
                  regex_pars=c("^b_", "^sd_")
                  )
```


```{r}
mdl1 <- add_criterion(mdl1, "waic")
print(mdl1$criteria$waic)
```

```{r}
mdl1 <- add_criterion(mdl1, "loo")
print(mdl1$criteria$loo)
plot(mdl1$criteria$loo)
```

```{r}

# Get posterior predictions for each tank
mdl1_draws <- add_epred_draws(frogs, mdl1) %>% 
  median_hdi() %>% 
  mutate(model="Intercept-Only")
  
```


## Varying Intercepts Model + predation

```{r results="hide"}
# Varying intercepts model + predation
mdl1a <- brm(surv | trials(density) ~ 1 + (1 | tank) + pred,
            prior = c(set_prior("normal(0,2)", class="Intercept"),
                      set_prior("exponential(1)", class="sd")),
            data=frogs,
            family=binomial(link="logit"),
            chains=4,
            cores=ncores,
            file_refit = "on_change",
            file = here("homework/mdl8-1a.rds")
            )

#get_variables(mdl1a)

```

```{r}
summary(mdl1a)

mcmc_plot(mdl1a, type="intervals",
          pars=c("^b_", "^sd_"),
          prob=0.5, prob_outer=0.95,
          point_est="median")
```

```{r}
mcmc_rank_overlay(mdl1a,           
                  regex_pars=c("^b_", "^sd_")
                  )
```

```{r}

# Get posterior predictions for each tank
mdl1a_draws <- add_epred_draws(frogs, mdl1a) %>% 
  median_hdi() %>% 
  mutate(model="Intercept+predation")
```

```{r}
mdl1a <- add_criterion(mdl1a, "waic")
print(mdl1a$criteria$waic)
```


```{r}
mdl1a <- add_criterion(mdl1a, "loo")
print(mdl1a$criteria$loo)
plot(mdl1a$criteria$loo)
```

## Varying Intercepts Model + size

```{r results="hide"}
# Varying intercepts model + size
mdl1b <- brm(surv | trials(density) ~ 1 + (1 | tank) + size,
            prior = c(set_prior("normal(0,2)", class="Intercept"),
                      set_prior("exponential(1)", class="sd")),
            data=frogs,
            family=binomial(link="logit"),
            chains=4,
            cores=ncores,
            file_refit = "on_change",
            file = here("homework/mdl8-1b.rds")
            )

#get_variables(mdl1b)

```

```{r}
summary(mdl1b)

mcmc_plot(mdl1b, type="intervals",
          pars=c("^b_", "^sd_"),
          prob=0.5, prob_outer=0.95,
          point_est="median")
```

```{r}
mcmc_rank_overlay(mdl1b,           
                  regex_pars=c("^b_", "^sd_")
                  )
```

```{r}
mdl1b <- add_criterion(mdl1b, "waic")
print(mdl1b$criteria$waic)
```


```{r}
mdl1b <- add_criterion(mdl1b, "loo")
print(mdl1b$criteria$loo)
plot(mdl1b$criteria$loo)
```

```{r}

# Get posterior predictions for each tank
mdl1b_draws <- add_epred_draws(frogs, mdl1b) %>% 
  median_hdi() %>% 
  mutate(model="Intercept+size")
  
```

## Varying Intercepts Model + size + predation

```{r results="hide"}
# Varying intercepts model + size * predation
mdl1c <- brm(surv | trials(density) ~ 1 + (1 | tank) + size * pred,
            prior = c(set_prior("normal(0,2)", class="Intercept"),
                      set_prior("exponential(1)", class="sd")),
            data=frogs,
            family=binomial(link="logit"),
            chains=4,
            cores=ncores,
            file_refit = "on_change",
            file = here("homework/mdl8-1c.rds")
            )

# get_variables(mdl1c)

```

```{r}
summary(mdl1c)

mcmc_plot(mdl1c, type="intervals",
          pars=c("^b_", "^sd_"),
          prob=0.5, prob_outer=0.95,
          point_est="median")
```

```{r}
mcmc_rank_overlay(mdl1c,           
                  regex_pars=c("^b_", "^sd_")
                  )
```

```{r}
mdl1c <- add_criterion(mdl1c, "waic")
print(mdl1c$criteria$waic)
```


```{r}
mdl1c <- add_criterion(mdl1c, "loo")
print(mdl1c$criteria$loo)
plot(mdl1c$criteria$loo)
```


```{r}

# Get posterior predictions for each tank
mdl1c_draws <- add_epred_draws(frogs, mdl1c) %>% 
  median_hdi() %>%
  mutate(model="Intercept+size*predation")
```

```{r}
conditional_effects(mdl1c) 
```

## Compare Models

```{r}
rbind(mdl1_draws, mdl1a_draws, mdl1b_draws, mdl1c_draws) %>% 
  ggplot() +
  geom_point(mapping=aes(x=tank, y=surv/density, 
                         color="observed")) +
  geom_point(mapping=aes(x=tank, y=.epred/density,
                         color="posterior prediction")) +
  facet_wrap(vars(model)) +
  labs(y="proportion survived")
  
```

Note: Not sure using WAIC/PSIS to compare the models makes sense in this case.  They approximate the cross-validation error, but since the data is grouped by tank, leaving out an observation in this case means leaving out an entire tank. From the paper _Practical Bayesian model evaluation using leave-one-out cross-validation and
WAIC_, when there are many observations per group then it will not work as well and K-fold CV should be used instead. We already know the estimates aren't reliable from the warning messages when previously calculating WAIC/PSIS for each model.  But I'm going to be lazy for now and proceed following the example in the book. 

```{r}
loo_compare(mdl1a, mdl1b, mdl1c, criterion = "loo")
```

```{r}
loo_compare(mdl1a, mdl1b, mdl1c, criterion = "waic")
```

The standard error of the differences is greater than the differences between the three models, so adding the _size_ and _predation_ predictors doesn't significantly improve the predictive performance. The 95% posterior credible intervals for the coefficients of _size_ and _size_:_predation_ both include zero which adds further justification for not adding them to the model.  However, if I had a scientific basis for including _predation_ in the model then I would keep it in the model since the 95% credible interval is clearly negative.

# Problem 2

```{r}
data("bangladesh", package="rethinking")

df <- bangladesh %>%
  select(woman, district, use.contraception) %>% 
  mutate(district = as.factor(district))
```


## Fixed Effects Model
```{r results="hide"}
mdl2a <- brm(use.contraception ~ 0 + district,
            prior = c(set_prior("normal(0,2)", class="b")),
            data=df,
            family=bernoulli(link="logit"),
            chains=4,
            cores=ncores,
            file_refit = "on_change",
            file = here("homework/mdl8-2a.rds")
)
```
```{r}
summary(mdl2a)
```

```{r}
mcmc_rank_overlay(mdl2a)
```

```{r}
# Get posterior predictions for each tank
mdl2a_draws <- add_epred_draws(newdata=data.frame(district=unique(df$district)),
                               mdl2a) %>% 
  median_hdi() %>% 
  mutate(model="Fixed Effects")
```


## Varying Intercepts Model

```{r}
mdl2b <- brm(use.contraception ~ 1 + ( 1 | district),
            prior = c(set_prior("normal(0,2)", class="Intercept"),
                      set_prior("normal(0,2)", class="sd")),
            data=df,
            family=bernoulli(link="logit"),
            chains=4,
            cores=ncores,
            file_refit = "on_change",
            file = here("homework/mdl8-2b.rds")
)
```

```{r}
summary(mdl2b)
```


```{r}
mcmc_rank_overlay(mdl2b, 
                  regex_pars=c("^b_", "^sd_")
                  )
```


```{r}
# Get posterior predictions for each tank
mdl2b_draws <- add_epred_draws(newdata=data.frame(district=unique(df$district)),
                               mdl2b) %>% 
  median_hdi() %>% 
  mutate(model="Varying Intercept")
```

## Compare Models

```{r}
df_summary <- df %>% 
  group_by(district) %>% 
  summarize(prop = sum(use.contraception)/n(),
            size = n())

rbind(mdl2a_draws, mdl2b_draws) %>% 
  ggplot() +
  geom_pointrange(mapping=aes(x=district, y=.epred,
                              ymin=.lower, ymax=.upper, 
                              color=model)) +
  geom_point(data=df_summary, mapping=aes(x=district, y=prop)) +
  facet_wrap(vars(model)) +
  theme(axis.text.x = element_text(angle = 90)) 
  
```

The varying intercept clearly "shrinks" the estimates toward the group mean.  It's most noticeable for districts 3, 10, 11, 24 and 49, which have proportions close to the extremes (0 or 1) and a small number of observations.

# Problem 3
 
```{r}
data("Trolley", package="rethinking")

df <- Trolley %>%
  select(response, action, intention, contact, id) 

```



## Partial-Pooling (Varying-Intercept)

```{r results='hide'}

mdl3a <- brm(response ~  1 + (1 | id) + intention + action + contact + action:intention + contact:intention,
           data=df,
           family=cumulative(link="logit"),
           chains=4,
           cores=ncores,
           file_refit = "on_change",
           file = here("homework/mdl8-3a.rds")
           )

```

```{r}
summary(mdl3a)
```

```{r}
mcmc_plot(mdl3a, type="intervals",
          pars=c("^b_"),
          prob=0.5, prob_outer=0.95,
          point_est="median")
```

```{r}
# Note: Intercept terms are when predictors are mean centered
# For our purposes, we care about b_Intercept terms in the 
# plots below
# See https://discourse.mc-stan.org/t/b-intercept-and-intercept-how-are-they-related/12933/4 
mcmc_rank_overlay(mdl3a, regex_pars=c("^b_", "sigma"))
```

## Complete pooling (single intercept)

```{r results='hide'}

mdl3b <- brm(response ~  1 + intention + action + contact + action:intention + contact:intention,
           data=df,
           family=cumulative(link="logit"),
           chains=4,
           cores=ncores,
           file_refit = "on_change",
           file = here("homework/mdl8-3b.rds")
           )

```

```{r}
summary(mdl3b)
```

```{r}
mcmc_plot(mdl3b, type="intervals",
          pars=c("^b_"),
          prob=0.5, prob_outer=0.95,
          point_est="median")
```

```{r}
# Note: Intercept terms are when predictors are mean centered
# For our purposes, we care about b_Intercept terms in the 
# plots below
# See https://discourse.mc-stan.org/t/b-intercept-and-intercept-how-are-they-related/12933/4 
mcmc_rank_overlay(mdl3b, regex_pars=c("^b_", "sigma"))
```

## Compare models

```{r}
mdl3a <- add_criterion(mdl3a, "waic")
mdl3b <- add_criterion(mdl3b, "waic")
```



